{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5915ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from math import ceil\n",
    "from sqlalchemy import create_engine, text\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# sys.path.append(\"D:/Github/note/module\")                        # for windows\n",
    "sys.path.append(\"/Users/xinc./Documents/GitHub/note\")    # for mac\n",
    "from module.get_info_JQC import GetInfoJQC\n",
    "from module.plot_func import plot, plot_scatter, plot_df_columns, plot_pdf, plot_dropped_positions, plot_sequence\n",
    "from module.performance_func import summarize_performance, mean_ttest\n",
    "from module.tools import compute_iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103b8fb",
   "metadata": {},
   "source": [
    "# download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = GetInfoJQC()\n",
    "client.config.database = \"QTSE_2025\"\n",
    "\n",
    "pg_uri = \"postgresql+psycopg2://devuser:DevPass123!@localhost:5432/t2330\"\n",
    "pg_engine = create_engine(pg_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e611871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting MSSQL server 192.168.0.180 / database QTSE_2025\n",
      "export to postgre -> postgresql+psycopg2://devuser:DevPass123!@localhost:5432/t2330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(53852) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f96ad15f4cd40cba16263509a4f1932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Exporting t2330 (chunks):   0%|          | 0/2520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export completed for t2330\n"
     ]
    }
   ],
   "source": [
    "symbol = \"2330\"\n",
    "start = \"2025-01-01\"\n",
    "end = \"2025-11-30\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    sid, dd, tt, v, dno, io, m, d, cv,\n",
    "    bp1, bz1, bp2, bz2, bp3, bz3, bp4, bz4, bp5, bz5,\n",
    "    sp1, sz1, sp2, sz2, sp3, sz3, sp4, sz4, sp5, sz5\n",
    "FROM dbo.T06\n",
    "WHERE sid = '{symbol}'\n",
    "    AND dd BETWEEN '{start}' AND '{end}'\n",
    "ORDER BY dd, tt\n",
    "\"\"\"\n",
    "\n",
    "pg_uri = \"postgresql+psycopg2://devuser:DevPass123!@localhost:5432/t2330\"\n",
    "table_name = f\"t{symbol}\"\n",
    "client.export_to_postgre(table_name = table_name, sql_query = query, postgre_uri = pg_uri, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea856fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改 col 名稱\n",
    "\n",
    "rename_map = {\n",
    "    \"sid\": \"stock_id\",\n",
    "    \"dd\": \"trade_date\",\n",
    "    \"tt\": \"transaction_time\",\n",
    "    \"v\": \"volume\",\n",
    "    \"dno\": \"declaration_no\",\n",
    "    \"io\": \"in_out\",\n",
    "    \"m\": \"amount\",\n",
    "    \"d\": \"price\",\n",
    "    \"cv\": \"trade_volume\",\n",
    "    \"bp1\": \"bid_1_price\",\n",
    "    \"bz1\": \"bid_1_volume\",\n",
    "    \"bp2\": \"bid_2_price\",\n",
    "    \"bz2\": \"bid_2_volume\",\n",
    "    \"bp3\": \"bid_3_price\",\n",
    "    \"bz3\": \"bid_3_volume\",\n",
    "    \"bp4\": \"bid_4_price\",\n",
    "    \"bz4\": \"bid_4_volume\",\n",
    "    \"bp5\": \"bid_5_price\",\n",
    "    \"bz5\": \"bid_5_volume\",\n",
    "    \"sp1\": \"ask_1_price\",\n",
    "    \"sz1\": \"ask_1_volume\",\n",
    "    \"sp2\": \"ask_2_price\",\n",
    "    \"sz2\": \"ask_2_volume\",\n",
    "    \"sp3\": \"ask_3_price\",\n",
    "    \"sz3\": \"ask_3_volume\",\n",
    "    \"sp4\": \"ask_4_price\",\n",
    "    \"sz4\": \"ask_4_volume\",\n",
    "    \"sp5\": \"ask_5_price\",\n",
    "    \"sz5\": \"ask_5_volume\"\n",
    "}\n",
    "\n",
    "table_name = \"t2330\"\n",
    "\n",
    "# 執行 rename\n",
    "with pg_engine.begin() as conn:\n",
    "    for old, new in rename_map.items():\n",
    "        conn.execute(text(f'ALTER TABLE public.{table_name} RENAME COLUMN \"{old}\" TO \"{new}\";'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 照時間排序\n",
    "\n",
    "table_name = \"t2330\"\n",
    "sorted_table = f\"{table_name}_sorted_tmp\"\n",
    "\n",
    "sort_sql = f\"\"\"\n",
    "DROP TABLE IF EXISTS public.{sorted_table};\n",
    "\n",
    "CREATE TABLE public.{sorted_table} AS\n",
    "SELECT *\n",
    "FROM public.{table_name}\n",
    "ORDER BY trade_date, transaction_time;\n",
    "\n",
    "ALTER TABLE public.{table_name} RENAME TO {table_name}_unsorted_backup;\n",
    "ALTER TABLE public.{sorted_table} RENAME TO {table_name};\n",
    "\"\"\"\n",
    "with pg_engine.begin() as conn:\n",
    "    conn.execute(text(sort_sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f00d3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a391604",
   "metadata": {},
   "source": [
    "# featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ea3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_uri = \"postgresql+psycopg2://devuser:DevPass123!@localhost:5432/t2330\"\n",
    "pg_engine = create_engine(pg_uri, future = True)\n",
    "\n",
    "start_date = \"2025-01-01\"\n",
    "end_date   = \"2025-11-30\"\n",
    "\n",
    "query = text(\"\"\"\n",
    "SELECT *\n",
    "FROM public.t2330\n",
    "ORDER BY trade_date, transaction_time\n",
    "\"\"\")\n",
    "\n",
    "with pg_engine.connect() as conn:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# 依「每天」切成多個 DataFrame\n",
    "dfs_by_day: dict[pd.Timestamp, pd.DataFrame] = {\n",
    "    day: group.reset_index(drop = True).copy()\n",
    "    for day, group in df.groupby(\"trade_date\", sort = True)\n",
    "}\n",
    "\n",
    "feature_frames = []\n",
    "for day, group in tqdm(dfs_by_day.items()):\n",
    "    g = group.copy()\n",
    "    trade_date = pd.to_datetime(day)\n",
    "    g[\"transaction_time\"] = pd.to_datetime(\n",
    "        g[\"trade_date\"].astype(str) + \" \" + g[\"transaction_time\"].astype(str),\n",
    "        format = \"ISO8601\"\n",
    "    )\n",
    "    close_ts = trade_date + pd.Timedelta(hours = 13, minutes = 30)\n",
    "    cutoff_ts = trade_date + pd.Timedelta(hours = 13, minutes = 25)\n",
    "    # price\n",
    "    g[\"mid_price\"] = (g[\"bid_1_price\"] + g[\"ask_1_price\"]) / 2\n",
    "    g[\"mid_price_delta\"] = g[\"mid_price\"].diff()\n",
    "    g[\"spread\"] = g[\"ask_1_price\"] - g[\"bid_1_price\"]\n",
    "    g[\"spread_delta\"] = g[\"spread\"].diff()\n",
    "    g[\"price_diff\"] = g[\"price\"].diff()\n",
    "    # momentum\n",
    "    g[\"price_delta\"] = np.where(g[\"price\"] != 0, g[\"price\"] - g[\"price\"].shift(1), np.nan)\n",
    "    g[\"momentum\"] = g[\"price\"].rolling(5).apply(lambda x: x.iloc[-1] - x.iloc[0])\n",
    "    # volatility\n",
    "    g[\"volatility_10\"] = g[\"price\"].rolling(10).std()\n",
    "    g[\"hl_range\"] = g[\"price\"].rolling(10).max() - g[\"price\"].rolling(10).min()\n",
    "    # order book\n",
    "    g[\"imbalance\"] = (g[\"bid_1_volume\"] - g[\"ask_1_volume\"]) / (g[\"bid_1_volume\"] + g[\"ask_1_volume\"])\n",
    "    g[\"delta_bid_1_volume\"] = g[\"bid_1_volume\"].diff()\n",
    "    g[\"delta_ask_1_volume\"] = g[\"ask_1_volume\"].diff()\n",
    "    # volume\n",
    "    g[\"vol_diff\"] = g[\"volume\"].diff()\n",
    "    g[\"vol_ma_10\"] = g[\"volume\"].rolling(10).mean()\n",
    "    # time\n",
    "    g[\"time_to_close\"] = (close_ts - g[\"transaction_time\"]).dt.total_seconds()\n",
    "    g[\"time_since_prev_trade\"] = (g[\"transaction_time\"] - (g[\"transaction_time\"].where(g[\"declaration_no\"] > 0).shift(1).ffill())).dt.total_seconds()\n",
    "    g[\"trade_intensity\"] = ((g[\"declaration_no\"] > 0).astype(int)).rolling(10, min_periods = 1).sum()\n",
    "    # indicator for whether this timestamp has an actual trade\n",
    "    g[\"is_trade\"] = (g[\"declaration_no\"] > 0).astype(int)\n",
    "    # interaction\n",
    "    g[\"imb_spread\"] = g[\"imbalance\"] * g[\"spread\"]\n",
    "    g[\"ret_vol\"] = g[\"price_delta\"] * g[\"volatility_10\"]\n",
    "    g[\"vol_imb\"] = g[\"volume\"] * g[\"imbalance\"]\n",
    "    # label: Close對最後有效成交價的漲跌（binary）\n",
    "    pre_close = g.loc[(g[\"declaration_no\"] > 0) & (g[\"transaction_time\"] < cutoff_ts), \"price\"]\n",
    "    baseline = pre_close.iloc[-1] if not pre_close.empty else g[\"price\"].iloc[-1]\n",
    "    g[\"label\"] = (g[\"price\"] > baseline).astype(int)\n",
    "    feature_frames.append(g)\n",
    "\n",
    "features = pd.concat(feature_frames, ignore_index = True)\n",
    "\n",
    "table_name = \"t2330_features\"\n",
    "chunksize = 5000\n",
    "num_chunks = ceil(len(features) / chunksize)\n",
    "\n",
    "with pg_engine.begin() as conn:\n",
    "    for i in tqdm(range(num_chunks), desc = \"writing\", unit = \"chunk\"):\n",
    "        start = i * chunksize\n",
    "        stop = start + chunksize\n",
    "        chunk = features.iloc[start:stop]\n",
    "\n",
    "        chunk.to_sql(\n",
    "            table_name,\n",
    "            con = conn,\n",
    "            schema = \"public\",\n",
    "            if_exists = \"replace\" if i == 0 else \"append\",\n",
    "            index = False,\n",
    "            method = \"multi\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2c0fa",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae62234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_uri = \"postgresql+psycopg2://devuser:DevPass123!@localhost:5432/t2330\"\n",
    "pg_engine = create_engine(pg_uri, future=True)\n",
    "\n",
    "query = text(\"\"\"\n",
    "SELECT *\n",
    "FROM public.t2330_features\n",
    "WHERE transaction_time >= date_trunc('day', transaction_time) + interval '13 hours'\n",
    "ORDER BY trade_date, transaction_time;\n",
    "\"\"\")\n",
    "\n",
    "with pg_engine.connect() as conn:\n",
    "    raw_slice = pd.read_sql_query(query, conn)\n",
    "\n",
    "features = raw_slice.sort_values([\"trade_date\", \"transaction_time\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "750280fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>transaction_time</th>\n",
       "      <th>volume</th>\n",
       "      <th>declaration_no</th>\n",
       "      <th>in_out</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "      <th>trade_volume</th>\n",
       "      <th>bid_1_price</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_ask_1_volume</th>\n",
       "      <th>vol_diff</th>\n",
       "      <th>vol_ma_10</th>\n",
       "      <th>time_to_close</th>\n",
       "      <th>time_since_prev_trade</th>\n",
       "      <th>trade_intensity</th>\n",
       "      <th>imb_spread</th>\n",
       "      <th>ret_vol</th>\n",
       "      <th>vol_imb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:00:00.051443</td>\n",
       "      <td>41835</td>\n",
       "      <td>-10809</td>\n",
       "      <td>0</td>\n",
       "      <td>3.829205e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41834.5</td>\n",
       "      <td>1799.948557</td>\n",
       "      <td>3.389979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.367438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19808.356983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:00:00.074741</td>\n",
       "      <td>41835</td>\n",
       "      <td>-10809</td>\n",
       "      <td>0</td>\n",
       "      <td>3.829205e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41834.6</td>\n",
       "      <td>1799.925259</td>\n",
       "      <td>3.413277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.367438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19808.356983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:00:00.083103</td>\n",
       "      <td>41835</td>\n",
       "      <td>-10809</td>\n",
       "      <td>0</td>\n",
       "      <td>3.829205e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41834.7</td>\n",
       "      <td>1799.916897</td>\n",
       "      <td>3.421639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.367930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19812.468732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:00:00.083278</td>\n",
       "      <td>41835</td>\n",
       "      <td>-10809</td>\n",
       "      <td>0</td>\n",
       "      <td>3.829205e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41834.8</td>\n",
       "      <td>1799.916722</td>\n",
       "      <td>3.421814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19816.578947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:00:00.084441</td>\n",
       "      <td>41835</td>\n",
       "      <td>-10809</td>\n",
       "      <td>0</td>\n",
       "      <td>3.829205e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41834.9</td>\n",
       "      <td>1799.915559</td>\n",
       "      <td>3.422977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19816.578947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:29:40.749100</td>\n",
       "      <td>44977</td>\n",
       "      <td>-12299</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290170e+10</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>11115</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44977.0</td>\n",
       "      <td>19.250900</td>\n",
       "      <td>281.065045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.856187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16697.147157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:29:45.765736</td>\n",
       "      <td>44977</td>\n",
       "      <td>-12299</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290170e+10</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>10220</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44977.0</td>\n",
       "      <td>14.234264</td>\n",
       "      <td>286.081681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.948777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26525.424880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:29:50.778281</td>\n",
       "      <td>44977</td>\n",
       "      <td>-12299</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290170e+10</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>8707</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44977.0</td>\n",
       "      <td>9.221719</td>\n",
       "      <td>291.094226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10799.013319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:29:55.792870</td>\n",
       "      <td>44977</td>\n",
       "      <td>-12299</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290170e+10</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>8173</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44977.0</td>\n",
       "      <td>4.207130</td>\n",
       "      <td>296.108815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.274126</td>\n",
       "      <td>-7.905694</td>\n",
       "      <td>-11461.271888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>2330</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025-11-05 13:30:00.000000</td>\n",
       "      <td>53150</td>\n",
       "      <td>12300</td>\n",
       "      <td>-8173</td>\n",
       "      <td>4.280837e+10</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>8173</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>649.0</td>\n",
       "      <td>8173.0</td>\n",
       "      <td>45794.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.315945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.903796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20237.347816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6753 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_id  trade_date           transaction_time  volume  declaration_no  \\\n",
       "0        2330  2025-11-05 2025-11-05 13:00:00.051443   41835          -10809   \n",
       "1        2330  2025-11-05 2025-11-05 13:00:00.074741   41835          -10809   \n",
       "2        2330  2025-11-05 2025-11-05 13:00:00.083103   41835          -10809   \n",
       "3        2330  2025-11-05 2025-11-05 13:00:00.083278   41835          -10809   \n",
       "4        2330  2025-11-05 2025-11-05 13:00:00.084441   41835          -10809   \n",
       "...       ...         ...                        ...     ...             ...   \n",
       "6748     2330  2025-11-05 2025-11-05 13:29:40.749100   44977          -12299   \n",
       "6749     2330  2025-11-05 2025-11-05 13:29:45.765736   44977          -12299   \n",
       "6750     2330  2025-11-05 2025-11-05 13:29:50.778281   44977          -12299   \n",
       "6751     2330  2025-11-05 2025-11-05 13:29:55.792870   44977          -12299   \n",
       "6752     2330  2025-11-05 2025-11-05 13:30:00.000000   53150           12300   \n",
       "\n",
       "      in_out        amount   price  trade_volume  bid_1_price  ...  \\\n",
       "0          0  3.829205e+10     0.0             0       1465.0  ...   \n",
       "1          0  3.829205e+10     0.0             0       1465.0  ...   \n",
       "2          0  3.829205e+10     0.0             0       1465.0  ...   \n",
       "3          0  3.829205e+10     0.0             0       1465.0  ...   \n",
       "4          0  3.829205e+10     0.0             0       1465.0  ...   \n",
       "...      ...           ...     ...           ...          ...  ...   \n",
       "6748       0  4.290170e+10  1465.0         11115       1465.0  ...   \n",
       "6749       0  4.290170e+10  1465.0         10220       1460.0  ...   \n",
       "6750       0  4.290170e+10  1465.0          8707       1460.0  ...   \n",
       "6751       0  4.290170e+10  1460.0          8173       1460.0  ...   \n",
       "6752   -8173  4.280837e+10  1460.0          8173       1460.0  ...   \n",
       "\n",
       "      delta_ask_1_volume  vol_diff  vol_ma_10  time_to_close  \\\n",
       "0                    0.0       0.0    41834.5    1799.948557   \n",
       "1                    0.0       0.0    41834.6    1799.925259   \n",
       "2                    0.0       0.0    41834.7    1799.916897   \n",
       "3                    0.0       0.0    41834.8    1799.916722   \n",
       "4                    0.0       0.0    41834.9    1799.915559   \n",
       "...                  ...       ...        ...            ...   \n",
       "6748                 0.0       0.0    44977.0      19.250900   \n",
       "6749               692.0       0.0    44977.0      14.234264   \n",
       "6750              1214.0       0.0    44977.0       9.221719   \n",
       "6751               132.0       0.0    44977.0       4.207130   \n",
       "6752               649.0    8173.0    45794.3       0.000000   \n",
       "\n",
       "      time_since_prev_trade  trade_intensity  imb_spread   ret_vol  \\\n",
       "0                  3.389979              1.0    2.367438       NaN   \n",
       "1                  3.413277              1.0    2.367438       NaN   \n",
       "2                  3.421639              1.0    2.367930       NaN   \n",
       "3                  3.421814              1.0    2.368421       NaN   \n",
       "4                  3.422977              1.0    2.368421       NaN   \n",
       "...                     ...              ...         ...       ...   \n",
       "6748             281.065045              0.0   -1.856187  0.000000   \n",
       "6749             286.081681              0.0    2.948777  0.000000   \n",
       "6750             291.094226              0.0    1.200504  0.000000   \n",
       "6751             296.108815              0.0   -1.274126 -7.905694   \n",
       "6752             300.315945              1.0   -1.903796  0.000000   \n",
       "\n",
       "           vol_imb  label  \n",
       "0     19808.356983      0  \n",
       "1     19808.356983      0  \n",
       "2     19812.468732      0  \n",
       "3     19816.578947      0  \n",
       "4     19816.578947      0  \n",
       "...            ...    ...  \n",
       "6748 -16697.147157      0  \n",
       "6749  26525.424880      0  \n",
       "6750  10799.013319      0  \n",
       "6751 -11461.271888      0  \n",
       "6752 -20237.347816      0  \n",
       "\n",
       "[6753 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ad79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# ---- 模型主要超參數；SEQ_LEN 代表要使用 13:24 前最後 3000 筆資料\n",
    "SEQ_LEN = 3000\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---- feature selection (only keep columns that exist in the table)\n",
    "feature_cols = [\n",
    "    \"price\",\n",
    "    \"mid_price\",\n",
    "    \"mid_price_delta\",\n",
    "    \"spread\",\n",
    "    \"spread_delta\",\n",
    "    \"price_diff\",\n",
    "    \"price_delta\",\n",
    "    \"momentum\",\n",
    "    \"volatility_10\",\n",
    "    \"hl_range\",\n",
    "    \"imbalance\",\n",
    "    \"delta_bid_1_volume\",\n",
    "    \"delta_ask_1_volume\",\n",
    "    \"vol_diff\",\n",
    "    \"vol_ma_10\",\n",
    "    \"time_to_close\",\n",
    "    \"time_since_prev_trade\",\n",
    "    \"trade_intensity\",\n",
    "    \"imb_spread\",\n",
    "    \"ret_vol\",\n",
    "    \"vol_imb\",\n",
    "    \"is_trade\",\n",
    "]\n",
    "available_features = [col for col in feature_cols if col in features.columns]\n",
    "if not available_features:\n",
    "    raise ValueError(\"No valid feature columns were found for the LSTM model.\")\n",
    "\n",
    "# ---- 時間欄位轉換並排序，確保序列是依時間遞增\n",
    "features = features.copy()\n",
    "features[\"trade_date\"] = pd.to_datetime(features[\"trade_date\"])\n",
    "features[\"transaction_time\"] = pd.to_datetime(features[\"transaction_time\"])\n",
    "features = features.sort_values([\"trade_date\", \"transaction_time\"]).reset_index(drop = True)\n",
    "if LABEL_COLUMN not in features.columns:\n",
    "    raise ValueError(f\"Feature table must contain '{LABEL_COLUMN}' for classification.\")\n",
    "\n",
    "def build_daily_sequences(df: pd.DataFrame, cols: list[str], seq_len: int):\n",
    "    \"\"\"Construct one sequence per day using 13:00-13:30 data and the last seq_len rows before 13:24.\"\"\"\n",
    "    sequences, labels, date_index = [], [], []\n",
    "    for trade_date, group in df.groupby(\"trade_date\", sort = True):\n",
    "        g = group.copy()\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        # fill gaps in intraday features to avoid breaking the LSTM input\n",
    "        g.loc[:, cols] = g[cols].ffill()\n",
    "        close_label = int(g[LABEL_COLUMN].iloc[-1])\n",
    "        cutoff_ts = pd.Timestamp(trade_date) + pd.Timedelta(hours = 13, minutes = 24)\n",
    "        history = g[(g[\"transaction_time\"] <= cutoff_ts)]\n",
    "        window = history.iloc[- seq_len:][cols].to_numpy()\n",
    "        sequences.append(window)\n",
    "        labels.append(close_label)\n",
    "        date_index.append(trade_date)\n",
    "    return np.array(sequences), np.array(labels), date_index\n",
    "\n",
    "sequence_data, price_targets, date_index = build_daily_sequences(features, available_features, SEQ_LEN)\n",
    "if len(sequence_data) < 20:\n",
    "    raise RuntimeError(\"Not enough daily sequences to train and evaluate the LSTM model.\")\n",
    "\n",
    "# keep chronological split to mimic walk-forward evaluation\n",
    "split_idx = max(int(len(sequence_data) * 0.8), 1)\n",
    "train_X, test_X = sequence_data[:split_idx], sequence_data[split_idx:]\n",
    "train_y, test_y = price_targets[:split_idx], price_targets[split_idx:]\n",
    "test_dates = date_index[split_idx:]\n",
    "\n",
    "# ---- normalize inputs only\n",
    "feature_scaler = StandardScaler()\n",
    "train_X = feature_scaler.fit_transform(train_X.reshape(-1, len(available_features))).reshape(train_X.shape)\n",
    "test_X = feature_scaler.transform(test_X.reshape(-1, len(available_features))).reshape(test_X.shape)\n",
    "\n",
    "# convert to tensors for PyTorch dataloaders\n",
    "train_tensor = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_targets = torch.tensor(train_y, dtype=torch.float32).unsqueeze(-1)\n",
    "test_tensor = torch.tensor(test_X, dtype=torch.float32)\n",
    "test_targets = torch.tensor(test_y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "full_train_ds = TensorDataset(train_tensor, train_targets)\n",
    "if len(full_train_ds) < 2:\n",
    "    raise RuntimeError(\"Need at least two training sequences to proceed.\")\n",
    "val_size = max(1, int(0.1 * len(full_train_ds)))\n",
    "val_size = min(val_size, len(full_train_ds) - 1)\n",
    "train_size = len(full_train_ds) - val_size\n",
    "train_ds, val_ds = random_split(full_train_ds, [train_size, val_size])\n",
    "test_ds = TensorDataset(test_tensor, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# class ClosePriceLSTM(nn.Module):\n",
    "#     \"\"\"Stacked LSTM + MLP head to predict the probability of a close-up day.\"\"\"\n",
    "#     def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout: float):\n",
    "#         super().__init__()\n",
    "#         self.lstm = nn.LSTM(\n",
    "#             input_size=input_size,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             dropout=dropout if num_layers > 1 else 0.0,\n",
    "#         )\n",
    "#         self.regressor = nn.Sequential(\n",
    "#             nn.Linear(hidden_size, hidden_size // 2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size // 2, 1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output, _ = self.lstm(x)\n",
    "#         last_hidden = output[:, -1, :]\n",
    "#         return self.regressor(last_hidden)\n",
    "\n",
    "# model = ClosePriceLSTM(\n",
    "#     input_size=len(available_features),\n",
    "#     hidden_size=HIDDEN_SIZE,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "#     dropout=DROPOUT,\n",
    "# ).to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# def run_epoch(loader: DataLoader, training: bool = True):\n",
    "#     \"\"\"Run one epoch through the loader while keeping/turning off gradients.\"\"\"\n",
    "#     model.train(mode=training)\n",
    "#     total_loss = 0.0\n",
    "#     for batch_x, batch_y in loader:\n",
    "#         batch_x = batch_x.to(device)\n",
    "#         batch_y = batch_y.to(device)\n",
    "#         if training:\n",
    "#             optimizer.zero_grad()\n",
    "#         preds = model(batch_x)\n",
    "#         loss = criterion(preds, batch_y)\n",
    "#         if training:\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#             optimizer.step()\n",
    "#         total_loss += loss.item() * batch_x.size(0)\n",
    "#     return total_loss / len(loader.dataset)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     train_loss = run_epoch(train_loader, training=True)\n",
    "#     val_loss = run_epoch(val_loader, training=False)\n",
    "#     if epoch == 1 or epoch % 5 == 0:\n",
    "#         print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n",
    "\n",
    "# # ---- inference on the hold-out set\n",
    "# model.eval()\n",
    "# all_logits, all_targets = [], []\n",
    "# with torch.no_grad():\n",
    "#     for batch_x, batch_y in test_loader:\n",
    "#         batch_x = batch_x.to(device)\n",
    "#         logits = model(batch_x).cpu().numpy().squeeze(-1)\n",
    "#         targets = batch_y.cpu().numpy().squeeze(-1)\n",
    "#         all_logits.append(logits)\n",
    "#         all_targets.append(targets)\n",
    "# all_logits = np.concatenate(all_logits)\n",
    "# all_targets = np.concatenate(all_targets)\n",
    "# probs = 1 / (1 + np.exp(-all_logits))\n",
    "# pred_labels = (probs >= 0.5).astype(int)\n",
    "\n",
    "# acc = accuracy_score(all_targets, pred_labels)\n",
    "# try:\n",
    "#     auc = roc_auc_score(all_targets, probs)\n",
    "# except ValueError:\n",
    "#     auc = float(\"nan\")\n",
    "#     print(\"ROC-AUC 無法計算（測試集中只有單一類別）。\")\n",
    "# print(f\"Test Accuracy: {acc:.3f} | ROC-AUC: {auc:.3f}\")\n",
    "# print(classification_report(all_targets, pred_labels, digits=3))\n",
    "\n",
    "# pred_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"trade_date\": test_dates,\n",
    "#         \"actual_label\": all_targets.astype(int),\n",
    "#         \"pred_label\": pred_labels,\n",
    "#         \"prob_up\": probs,\n",
    "#     }\n",
    "# )\n",
    "# display(pred_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b18f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465a103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JQC_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
